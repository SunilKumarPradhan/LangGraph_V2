---
title: "NoteSmith - Lecture Notes Generator"
layout: default
nav_order: 14
parent: "Lecture Notes"
description: "Lecture notes: NoteSmith - Lecture Notes Generator"
last_modified_date: 2026-01-18
source_transcript: "015_LangGraph + SQLite _ Chatbot with Database Integration _ CampusX"
generated_by: "NoteSmith"
---

# NoteSmith - Lecture Notes Generator

# Persistent Database Storage for LangGraph Chatbots

---

## ğŸ“‘ Table of Contents

1. [Overview](#overview)
2. [Understanding the Problem](#understanding-the-problem)
3. [Checkpoint Savers in LangGraph](#checkpoint-savers-in-langgraph)
4. [Backend Implementation](#backend-implementation)
5. [Database Visualization](#database-visualization)
6. [Frontend Integration](#frontend-integration)
7. [Complete Working Example](#complete-working-example)
8. [Quick Reference](#quick-reference)
9. [Summary Table](#summary-table)
10. [Key Takeaways](#key-takeaways)
11. [Edge Cases & Common Mistakes](#edge-cases--common-mistakes)
12. [Interview Questions](#interview-questions)

---

## ğŸ¯ Overview

### What This Covers
This tutorial demonstrates how to add **persistent database storage** to a LangGraph chatbot, ensuring conversation history survives application restarts and page refreshes.

### Prerequisites
- Basic understanding of LangGraph workflows
- Familiarity with Python and Streamlit
- Previous knowledge of chatbot development
- Understanding of threads and conversation management

### Why It Matters
**The Problem**: Using `MemorySaver` (in-memory storage) means all conversations are lost when:
- The application closes
- The page refreshes
- The server restarts

**The Solution**: Implementing database-backed checkpoint savers ensures:
- âœ… Conversations persist permanently
- âœ… Users can resume chats days later
- âœ… Multiple conversation threads are maintained
- âœ… Production-ready chat applications

### Real-World Applications
- Customer support chatbots
- Personal AI assistants
- Educational tutoring systems
- Healthcare consultation bots
- E-commerce shopping assistants

---

## ğŸ” Understanding the Problem

### Current State (In-Memory Storage)

> **MemorySaver**: Stores all conversation data in RAM (Random Access Memory). When the program terminates, all data is lost.

**Limitations:**
```python
# Using MemorySaver (temporary storage)
from langgraph.checkpoint.memory import MemorySaver

checkpointer = MemorySaver()
# âŒ Data lost on application restart
# âŒ Data lost on page refresh
# âŒ Not suitable for production
```

### Desired State (Database Storage)

```python
# Using SqliteSaver (persistent storage)
from langgraph.checkpoint.sqlite import SqliteSaver

checkpointer = SqliteSaver(conn)
# âœ… Data persists after restart
# âœ… Data survives page refresh
# âœ… Production-ready solution
```

---

## ğŸ—„ï¸ Checkpoint Savers in LangGraph

### Types of Checkpoint Savers

| Checkpoint Saver | Storage Type | Use Case | Persistence | Production Ready |
|-----------------|--------------|----------|-------------|------------------|
| **MemorySaver** | RAM | Learning/Testing | âŒ No | âŒ No |
| **SqliteSaver** | SQLite Database | Prototyping/Small Apps | âœ… Yes | âš ï¸ Limited |
| **PostgresSaver** | PostgreSQL Database | Production Applications | âœ… Yes | âœ… Yes |

### When to Use Each

**MemorySaver:**
- Quick prototyping
- Learning LangGraph concepts
- Temporary testing
- Single-session applications

**SqliteSaver:**
- Small to medium applications
- Local development
- Proof of concepts
- Learning database integration

**PostgresSaver:**
- Large-scale production apps
- Multi-user systems
- High-traffic applications
- Enterprise solutions

---

## ğŸ”§ Backend Implementation

### Step 1: Install Required Library

```bash
# Install the SQLite checkpoint library
pip install langgraph-checkpoint-sqlite
```

**What this does:**
- Adds SQLite database support to LangGraph
- Provides `SqliteSaver` class for persistent storage
- Currently a separate package (may be integrated into LangGraph core in future)

### Step 2: Import Required Modules

```python
# Replace MemorySaver import with SqliteSaver
from langgraph.checkpoint.sqlite import SqliteSaver
import sqlite3
```

**Line-by-line explanation:**
- `from langgraph.checkpoint.sqlite import SqliteSaver`: Imports the database-backed checkpoint saver
- `import sqlite3`: Python's built-in SQLite database module for creating database connections

### Step 3: Create Database Connection

```python
# Create SQLite database connection
conn = sqlite3.connect(
    "chatbot.db",              # Database filename
    check_same_thread=False    # Allow multi-threading
)
```

**Parameter breakdown:**

**`"chatbot.db"`**:
- Name of the database file
- Will be created in project directory if doesn't exist
- Extension `.db` indicates SQLite database

**`check_same_thread=False`**:
- **Why needed**: SQLite by default restricts database access to the thread that created it
- **The problem**: Streamlit and LangGraph use multiple threads for handling concurrent conversations
- **The solution**: Setting this to `False` removes the thread restriction
- **Trade-off**: Slightly less safe, but necessary for multi-threaded applications

### Step 4: Initialize SqliteSaver

```python
# Create checkpoint saver with database connection
checkpointer = SqliteSaver(conn)
```

**What happens here:**
- Creates a checkpoint saver object
- Links it to the SQLite database
- Automatically handles saving/loading conversation state
- Creates necessary tables in the database

### Complete Backend Code

```python
# langgraph_database_backend.py

from langgraph.checkpoint.sqlite import SqliteSaver
import sqlite3
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.graph.message import add_messages

# Step 1: Create database connection
conn = sqlite3.connect(
    "chatbot.db",
    check_same_thread=False
)

# Step 2: Initialize SqliteSaver
checkpointer = SqliteSaver(conn)

# Step 3: Define your LLM
llm = ChatOpenAI(model="gpt-4", temperature=0.7)

# Step 4: Define chat node
def chat_node(state: MessagesState):
    """Process user message and generate AI response"""
    return {"messages": [llm.invoke(state["messages"])]}

# Step 5: Build workflow
workflow = StateGraph(MessagesState)
workflow.add_node("chat", chat_node)
workflow.add_edge(START, "chat")
workflow.add_edge("chat", END)

# Step 6: Compile with database checkpointer
chatbot = workflow.compile(checkpointer=checkpointer)
```

### Testing the Backend

```python
# Test script to verify database storage
from langgraph_database_backend import chatbot

# Configuration with thread ID
config = {
    "configurable": {
        "thread_id": "thread_1"
    }
}

# Send first message
response = chatbot.invoke(
    {"messages": [{"role": "user", "content": "Hi, my name is Nitish"}]},
    config=config
)
print(response)

# Close and restart program, then test memory
response = chatbot.invoke(
    {"messages": [{"role": "user", "content": "What is my name?"}]},
    config=config
)
print(response)
# Output: "Your name is Nitish"
# âœ… Proves data persisted across program restarts!
```

---

## ğŸ‘ï¸ Database Visualization

### Installing SQLite Viewer Extension

**For VS Code:**
1. Go to Extensions (Ctrl+Shift+X)
2. Search "SQLite Viewer"
3. Install "SQLite Viewer" by Florian Klampfer
4. Click on `chatbot.db` file to view contents

### Understanding Database Structure

**Checkpoints Table:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ thread_id   â”‚ checkpoint â”‚ metadata          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ thread_1    â”‚ 1          â”‚ {start checkpoint}â”‚
â”‚ thread_1    â”‚ 2          â”‚ {chat checkpoint} â”‚
â”‚ thread_1    â”‚ 3          â”‚ {end checkpoint}  â”‚
â”‚ thread_2    â”‚ 1          â”‚ {start checkpoint}â”‚
â”‚ thread_2    â”‚ 2          â”‚ {chat checkpoint} â”‚
â”‚ thread_2    â”‚ 3          â”‚ {end checkpoint}  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why Multiple Checkpoints Per Thread?**

Each workflow execution creates **3 checkpoints**:
1. **Start checkpoint**: Before processing begins
2. **Chat checkpoint**: After LLM generates response
3. **End checkpoint**: After workflow completes

**Example:**
```python
# First message: "Hi, my name is Nitish"
# Creates: checkpoint 1, 2, 3 for thread_1

# Second message: "What is my name?"
# Creates: checkpoint 4, 5, 6 for thread_1

# Total: 6 checkpoints for thread_1
```

### Viewing Conversation Data

```python
# Access checkpoint details
checkpoints = checkpointer.list(None)  # Get all checkpoints

for checkpoint in checkpoints:
    config = checkpoint.config
    thread_id = config["configurable"]["thread_id"]
    print(f"Thread: {thread_id}")
    print(f"Messages: {checkpoint.checkpoint['messages']}")
```

---

## ğŸ¨ Frontend Integration

### The Challenge

**Previous approach (with MemorySaver):**
```python
# Initialize with empty list (no past threads)
if "chat_threads" not in st.session_state:
    st.session_state.chat_threads = []  # âŒ Loses past conversations
```

**New approach (with SqliteSaver):**
```python
# Initialize by retrieving existing threads from database
if "chat_threads" not in st.session_state:
    st.session_state.chat_threads = retrieve_all_threads()  # âœ… Loads past conversations
```

### Step 1: Create Thread Retrieval Function

```python
# In langgraph_database_backend.py

def retrieve_all_threads():
    """
    Retrieves all unique thread IDs from the database.
    
    Returns:
        list: List of unique thread IDs (e.g., ['thread_1', 'thread_2'])
    """
    # Set to store unique thread IDs
    all_threads = set()
    
    # Get all checkpoints from database
    checkpoints = checkpointer.list(None)  # None = get all threads
    
    # Extract thread IDs from each checkpoint
    for checkpoint in checkpoints:
        # Navigate to thread_id in nested structure
        thread_id = checkpoint.config["configurable"]["thread_id"]
        all_threads.add(thread_id)  # Set automatically handles duplicates
    
    # Convert set to list and return
    return list(all_threads)
```

**Code breakdown:**

**`checkpointer.list(None)`**:
- `None`: Retrieves checkpoints from ALL threads
- Alternative: `checkpointer.list({"configurable": {"thread_id": "thread_1"}})` for specific thread
- Returns: Generator object containing checkpoint tuples

**`checkpoint.config["configurable"]["thread_id"]`**:
- `checkpoint`: Tuple containing checkpoint data
- `.config`: Dictionary with configuration metadata
- `["configurable"]`: Nested dictionary with thread information
- `["thread_id"]`: The actual thread identifier

**`set()` vs `list()`**:
- **Set**: Automatically removes duplicates (thread_1 appears only once)
- **List**: Would contain duplicates (thread_1, thread_1, thread_1...)
- We convert back to list at the end for compatibility

### Step 2: Update Frontend Code

```python
# streamlit_frontend_database.py

import streamlit as st
from langgraph_database_backend import chatbot, retrieve_all_threads

# Page configuration
st.set_page_config(page_title="Persistent Chatbot", page_icon="ğŸ’¬")
st.title("ğŸ’¬ Chatbot with Database Storage")

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "current_thread" not in st.session_state:
    st.session_state.current_thread = None

# âœ… NEW: Load existing threads from database
if "chat_threads" not in st.session_state:
    st.session_state.chat_threads = retrieve_all_threads()  # Fetch from DB

# Sidebar for thread management
with st.sidebar:
    st.header("Conversation Threads")
    
    # Button to create new thread
    if st.button("â• New Chat"):
        new_thread_id = f"thread_{len(st.session_state.chat_threads) + 1}"
        st.session_state.chat_threads.append(new_thread_id)
        st.session_state.current_thread = new_thread_id
        st.session_state.messages = []
        st.rerun()
    
    # Display existing threads
    for thread in st.session_state.chat_threads:
        if st.button(thread, key=thread):
            st.session_state.current_thread = thread
            # Load messages for this thread
            st.session_state.messages = load_thread_messages(thread)
            st.rerun()

# Display current thread
if st.session_state.current_thread:
    st.subheader(f"Thread: {st.session_state.current_thread}")
    
    # Display message history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
    
    # Chat input
    if prompt := st.chat_input("Type your message..."):
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # Display user message
        with st.chat_message("user"):
            st.write(prompt)
        
        # Get AI response with streaming
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            # Configuration for current thread
            config = {
                "configurable": {
                    "thread_id": st.session_state.current_thread
                }
            }
            
            # Stream response
            for chunk in chatbot.stream(
                {"messages": [{"role": "user", "content": prompt}]},
                config=config,
                stream_mode="messages"
            ):
                if hasattr(chunk, 'content'):
                    full_response += chunk.content
                    message_placeholder.write(full_response + "â–Œ")
            
            message_placeholder.write(full_response)
        
        # Add assistant message
        st.session_state.messages.append({"role": "assistant", "content": full_response})

else:
    st.info("ğŸ‘ˆ Select a thread or create a new chat to begin")

def load_thread_messages(thread_id):
    """Load message history for a specific thread from database"""
    config = {"configurable": {"thread_id": thread_id}}
    
    # Get state from database
    state = chatbot.get_state(config)
    
    # Extract messages
    messages = []
    if state and "messages" in state.values:
        for msg in state.values["messages"]:
            messages.append({
                "role": msg.type,  # 'human' or 'ai'
                "content": msg.content
            })
    
    return messages
```

---

## ğŸš€ Complete Working Example

### Project Structure

```
chatbot_project/
â”‚
â”œâ”€â”€ langgraph_database_backend.py    # Backend logic
â”œâ”€â”€ streamlit_frontend_database.py   # Frontend UI
â”œâ”€â”€ chatbot.db                        # SQLite database (auto-created)
â”œâ”€â”€ .env                              # API keys
â””â”€â”€ requirements.txt                  # Dependencies
```

### requirements.txt

```txt
langgraph
langgraph-checkpoint-sqlite
langchain-openai
streamlit
python-dotenv
```

### Running the Application

```bash
# Step 1: Install dependencies
pip install -r requirements.txt

# Step