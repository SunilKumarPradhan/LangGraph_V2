---
title: "NoteSmith - Lecture Notes Generator"
layout: default
nav_order: 16
parent: "Lecture Notes"
description: "Lecture notes: NoteSmith - Lecture Notes Generator"
last_modified_date: 2026-01-18
source_transcript: "018_Tools in LangGraph _ Agentic AI using LangGraph _ CampusX"
generated_by: "NoteSmith"
---

# NoteSmith - Lecture Notes Generator

# Adding Tools to LangGraph Chatbots: Complete Guide

---

## Table of Contents

1. [Overview](#overview)
2. [What Are Tools in LangGraph?](#what-are-tools-in-langgraph)
3. [Core Concepts](#core-concepts)
4. [Building Your First Tool-Enabled Workflow](#building-your-first-tool-enabled-workflow)
5. [Three Essential Tools Implementation](#three-essential-tools-implementation)
6. [Integrating Tools into Existing Chatbot](#integrating-tools-into-existing-chatbot)
7. [Advanced Workflow Patterns](#advanced-workflow-patterns)
8. [Frontend Integration with Streamlit](#frontend-integration-with-streamlit)
9. [Quick Reference](#quick-reference)
10. [Summary Table](#summary-table)
11. [Key Takeaways](#key-takeaways)
12. [Edge Cases & Common Mistakes](#edge-cases--common-mistakes)
13. [Interview Questions](#interview-questions)

---

## Overview

### ğŸ“š What This Covers

This lecture teaches you how to transform a basic LangGraph chatbot into an **agentic AI system** capable of performing actions using tools. You'll learn to add three powerful capabilities:

1. **Calculator Tool** - Perform numerical calculations
2. **Internet Search Tool** - Search the web using DuckDuckGo
3. **Stock Price Tool** - Fetch real-time stock prices

### Prerequisites

- Basic understanding of LangGraph (state graphs, nodes, edges)
- Familiarity with LangChain tools (recommended: watch the LangChain playlist video on tools)
- Python programming knowledge
- Understanding of LLMs and chat interfaces

### Why This Matters

**Current Limitation**: Your chatbot can only *talk* - it cannot *act*.

**After This Tutorial**: Your chatbot will intelligently decide when to chat normally vs. when to execute actions using tools.

**Real-World Applications**:
- Customer service bots that can check order status
- Financial assistants that calculate and fetch live data
- Research assistants that search the internet
- Multi-step reasoning agents that chain tool calls

---

## What Are Tools in LangGraph?

### ğŸ”§ Definition

> **Tools** are external functions or APIs that your LLM can invoke to perform specific actions beyond text generation. They act as the "hands" of your AI, enabling it to interact with the world.

### Why Tools Are Necessary

**Without Tools**:
```
User: "What's 654 Ã— 713?"
LLM: "Approximately 466,302" âŒ (may be inaccurate)
```

**With Tools**:
```
User: "What's 654 Ã— 713?"
LLM: *calls calculator tool*
Tool: 466,302
LLM: "The product of 654 and 713 is 466,302" âœ…
```

### Types of Tools

| Type | Description | Example |
|------|-------------|---------|
| **Pre-built** | Ready-made tools from LangChain | DuckDuckGo Search, Wikipedia, Arxiv |
| **Custom** | Tools you create for specific needs | Calculator, Stock Price Fetcher, Database Query |

---

## Core Concepts

### ğŸ¯ 1. Tool Node

**What It Is**:
A special pre-built node in LangGraph that acts as a bridge between your graph and external tools.

**Key Characteristics**:
- **Pre-built**: You don't write it from scratch
- **Auto-routing**: Automatically routes requests to the correct tool
- **Tool executor**: Executes the tool and returns results

**Code Structure**:
```python
from langgraph.prebuilt import ToolNode

# Create a list of tools
tools = [search_tool, calculator_tool, stock_tool]

# Create tool node
tool_node = ToolNode(tools)
```

**How It Works**:
1. Receives tool call request from LLM
2. Identifies which tool to execute
3. Passes the correct input to that tool
4. Returns tool output back to the graph

---

### ğŸ”€ 2. Tools Condition

**What It Is**:
A pre-built conditional edge function that decides whether to route to tools or end the conversation.

**Decision Logic**:
```
User Query â†’ Chat Node â†’ Tools Condition
                              â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â†“                   â†“
              Tool Node              End Node
           (action needed)      (normal chat)
```

**Code Implementation**:
```python
from langgraph.prebuilt import tools_condition

# Add conditional edge
graph.add_conditional_edges(
    "chat_node",
    tools_condition,
    {
        "tools": "tool_node",    # If tools needed
        "end": END               # If normal chat
    }
)
```

**When It Routes to Tools**:
- User asks for calculations
- User requests internet search
- User needs real-time data
- Any query requiring external action

**When It Routes to End**:
- General conversation
- Questions answerable by LLM knowledge
- Greetings and casual chat

---

### ğŸ”„ 3. The Loop Pattern (Critical Concept)

**Problem with Simple Flow**:
```
Start â†’ Chat Node â†’ Tool Node â†’ End
```

**Issues**:
1. âŒ Tool output is raw (JSON, technical format)
2. âŒ Cannot perform multi-step reasoning
3. âŒ No refinement of results

**Solution: Add Loop Back**:
```
Start â†’ Chat Node â‡„ Tool Node â†’ End
         â†‘____________â†“
```

**Why This Works**:

**Example: Multi-Step Query**
```
Query: "What's Apple's stock price? How much for 50 shares?"

Step 1: Chat Node â†’ "Need stock price" â†’ Tool Node
Step 2: Tool Node â†’ Returns $150 â†’ Chat Node
Step 3: Chat Node â†’ "Need calculation" â†’ Tool Node  
Step 4: Tool Node â†’ Returns 150 Ã— 50 = 7500 â†’ Chat Node
Step 5: Chat Node â†’ "All info gathered" â†’ End
        Output: "Apple is $150. 50 shares cost $7,500"
```

**Code for Loop**:
```python
# Add edge from tool back to chat
graph.add_edge("tool_node", "chat_node")

# This creates the loop pattern
```

---

## Building Your First Tool-Enabled Workflow

### ğŸ“ Step-by-Step Implementation

#### Step 1: Import Required Libraries

```python
# Core LangGraph imports
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode, tools_condition

# LangChain imports
from langchain_openai import ChatOpenAI
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.tools import tool

# State management
from typing import Annotated
from langgraph.graph.message import add_messages
from langchain_core.messages import BaseMessage

# Environment
from dotenv import load_dotenv
import os
```

**What Each Import Does**:
- `StateGraph`: Creates the workflow graph
- `ToolNode`: Handles tool execution
- `tools_condition`: Routes between chat and tools
- `ChatOpenAI`: The LLM we'll use
- `DuckDuckGoSearchRun`: Pre-built search tool
- `tool`: Decorator to create custom tools

---

#### Step 2: Load Environment and Create LLM

```python
# Load API keys
load_dotenv()

# Create LLM instance
llm = ChatOpenAI(
    model="gpt-4",
    temperature=0  # Deterministic for tool calling
)
```

**Why temperature=0?**
Tool calling requires precision. We don't want creative variations in tool selection.

---

#### Step 3: Create Tools

##### ğŸ” Tool 1: DuckDuckGo Search (Pre-built)

```python
# Pre-built tool - just instantiate
search_tool = DuckDuckGoSearchRun()
```

**What it does**: Searches the internet and returns results.

**When to use**: 
- Current events
- Real-time information
- Facts not in LLM training data

---

##### ğŸ§® Tool 2: Calculator (Custom)

```python
@tool
def calculator(
    first_number: float,
    second_number: float,
    operation: str
) -> float:
    """
    Performs basic arithmetic operations.
    
    Args:
        first_number: First number
        second_number: Second number  
        operation: One of 'add', 'subtract', 'multiply', 'divide'
    
    Returns:
        Result of the calculation
    """
    if operation == "add":
        return first_number + second_number
    elif operation == "subtract":
        return first_number - second_number
    elif operation == "multiply":
        return first_number * second_number
    elif operation == "divide":
        if second_number == 0:
            return "Error: Division by zero"
        return first_number / second_number
    else:
        return "Error: Invalid operation"
```

**Breaking Down the Code**:

1. **`@tool` decorator**: Converts function into LangChain tool
2. **Type hints**: `float`, `str` help LLM understand expected inputs
3. **Docstring**: **CRITICAL** - LLM reads this to decide when to use the tool
4. **Error handling**: Prevents division by zero

**How LLM Uses This**:
```
User: "What's 25 Ã— 4?"
LLM thinks: "I need calculator tool"
LLM calls: calculator(25, 4, "multiply")
Tool returns: 100
LLM responds: "The result is 100"
```

---

##### ğŸ“ˆ Tool 3: Stock Price Fetcher (Custom)

```python
import requests

@tool
def get_stock_price(ticker: str) -> dict:
    """
    Fetches current stock price for a given ticker symbol.
    
    Args:
        ticker: Stock ticker symbol (e.g., 'AAPL' for Apple)
    
    Returns:
        Dictionary with stock information
    """
    api_key = os.getenv("ALPHA_VANTAGE_API_KEY")
    url = f"https://www.alphavantage.co/query"
    
    params = {
        "function": "GLOBAL_QUOTE",
        "symbol": ticker,
        "apikey": api_key
    }
    
    try:
        response = requests.get(url, params=params)
        data = response.json()
        return data
    except Exception as e:
        return {"error": str(e)}
```

**API Setup**:
1. Go to [alphavantage.co](https://www.alphavantage.co/)
2. Sign up for free API key
3. Add to `.env` file:
   ```
   ALPHA_VANTAGE_API_KEY=your_key_here
   ```

**Limitations**:
- Free tier: 5 API calls/minute, 500/day
- Don't share your API key

---

#### Step 4: Bind Tools to LLM

```python
# Create tools list
tools = [search_tool, calculator, get_stock_price]

# Bind tools to LLM
llm_with_tools = llm.bind_tools(tools)
```

**What `bind_tools` Does**:
- Tells LLM these tools are available
- LLM can now generate tool calls
- Enables function calling capability

---

#### Step 5: Define State

```python
from typing import TypedDict

class State(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
```

**State Explanation**:
- `messages`: List of all conversation messages
- `add_messages`: Reducer function that appends new messages
- Same state structure as basic chatbot

---

#### Step 6: Create Chat Node

```python
def chat_node(state: State) -> State:
    """
    Main chat node that calls LLM with tools.
    """
    # Get all messages from state
    messages = state["messages"]
    
    # Call LLM with tools bound
    response = llm_with_tools.invoke(messages)
    
    # Return updated state
    return {"messages": [response]}
```

**What Happens Here**:
1. Receives current conversation state
2. Passes all messages to LLM
3. LLM decides: chat normally OR call a tool
4. Returns response (either text or tool call)

---

#### Step 7: Build the Graph

```python
# Initialize graph
graph = StateGraph(State)

# Add nodes
graph.add_node("chat_node", chat_node)
graph.add_node("tool_node", ToolNode(tools))

# Add edges
graph.add_edge("__start__", "chat_node")  # Start â†’ Chat

# Conditional edge from chat
graph.add_conditional_edges(
    "chat_node",
    tools_condition,
    {
        "tools": "tool_node",  # If tools needed
        "end": END             # If normal chat
    }
)

# Loop back from tools to chat
graph.add_edge("tool_node", "chat_node")

# Compile
chatbot = graph.compile()
```

**Graph Structure Visualization**:
```
    START
      â†“
  Chat Node â†â”€â”€â”€â”€â”€â”€â”
      â†“            â”‚
  [Decision]       â”‚
   â†™     â†˜         â”‚
Tool    END        â”‚
Node               â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ§ª Testing the Workflow

#### Test 1: Normal Chat

```python
response = chatbot.invoke({
    "messages": [{"role": "user", "content": "Hello!"}]
})

print(response["messages"][-1].content)
# Output: "Hi there! How can I assist you today?"
```

**Flow**: Start â†’ Chat â†’ End (no tools used)

---

#### Test 2: Calculator Tool

```python
response = chatbot.invoke({
    "messages": [{"role": "user", "content": "What is 654 Ã— 713?"}]
})

print(response["messages"][-1].content)
# Output: "The product of 654 and 713 is 466,302"
```

**Flow**: 
1. Start â†’ Chat (detects calculation needed)
2. Chat â†’ Tool (calls calculator)
3. Tool â†’ Chat (returns 466,302)
4. Chat â†’ End (formats response)

---

#### Test 3: Stock Price Tool

```python
response = chatbot.invoke({
    "messages": [{"role": "user", "content": "What's Tesla's stock price?"}]
})

print(response["messages"][-1].content)
# Output: "The current stock price of Tesla is $323.45"
```

**Flow**: Start â†’ Chat â†’ Tool (stock API) â†’ Chat â†’ End

---

#### Test 4: Multi-Step Reasoning

```python
response = chatbot.invoke({
    "messages": [{
        "role": "user", 
        "content": "Who owns YouTube? Find their stock price."
    }]
})
```

**Complex Flow**:
1. Chat â†’ Tool (DuckDuckGo search for "who owns YouTube")
2. Tool â†’ Chat (returns "Google/Alphabet")
3. Chat â†’ Tool (get_stock_price for "GOOGL")
4. Tool â†’ Chat (returns stock data)
5. Chat â†’ End (formatted answer)

**Output**: "YouTube is owned by Google (Alphabet Inc.). The current stock price of Google is $154.32"

---

## Three Essential Tools Implementation

### ğŸ” Tool 1: Internet Search (DuckDuckGo)

#### Why DuckDuckGo?

| Feature | DuckDuckGo | Google |
|---------|------------|--------|
| API Access | Free, no key needed | Requires API key + billing |
| Rate Limits | Generous | Strict limits |
| Privacy | High | Lower |
| LangChain Support | Built-in | Requires setup |

#### Complete Implementation

```python
from langchain_community.tools import DuckDuckGoSearchRun

# Simple instantiation
search_tool = DuckDuckGoSearchRun()

# With custom parameters
search_tool = DuckDuckGoSearchRun(
    max_results=5,  # Number of results to return
    backend="api"   # Use API backend
)
```

#### Usage Example

```python
# Direct tool call (for testing)
result = search_tool.invoke("latest news India")